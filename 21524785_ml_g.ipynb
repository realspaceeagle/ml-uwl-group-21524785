{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4f4671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03e893a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dbf5d208",
   "metadata": {},
   "source": [
    "### 1. Project Synopsis\n",
    " \n",
    " \n",
    " \n",
    "- As the result of the effort of the White House Office of Science and Technology Policy (OSTP) working together with coalition research groups and companies (including Kaggle) to prepare the COVID-19 Open Research Dataset (CORD-19) in order to address key open scientific questions on COVID-19, Kaggle launched a companion COVID-19 forecasting challenges to help answer a subset of those questions.\n",
    " \n",
    " \n",
    "- On the basis of the Kaggleâ€™s challenge, in this project, your team is challenged to develop a ML model to predict the cumulative number of COVID19 confirmed cases and the number of resulting fatalities across the world, and is accurate in forecasting for future days. For the forecasting task, quantile estimates of the confirmed cases and fatalities are calculated based on the outcome of the predictive model you developed using the standard metric called Weighted Pinball Loss defined by Kaggle.  Ultimately, the goal of this challenge is to provide better methods for estimates that can assist medical and governmental institutions to prepare and adjust as pandemics unfold.\n",
    " \n",
    " \n",
    "- The dataset files for this challenge is available on Kaggle, in which the data source is originated from John Hopkins CSSE.  This dataset includes all the necessary variable columns to make predictions and forecasting.  Nevertheless, you are encouraged to join in many more useful external datasets to enrich the prediction/forecasting.\n",
    " \n",
    " \n",
    "- Your team is expected to establish hypotheses of predictive insights gleaning from the dataset by formulating \n",
    "\n",
    "\n",
    "- a number of questions and plausible answer for those questions as part of your EDA workflow. Some example questions, not limited to are:\n",
    "\n",
    "\n",
    "    - Which country is driving the growth and why?\n",
    "    - Which country is recovering?\n",
    "    - How the spreading pattern across the world looks like?\n",
    "    - Cases and death trend?\n",
    " \n",
    " \n",
    "- Your team is then expected to prepare the data and develop ML model suitable to meet the prediction objectives. \n",
    "\n",
    "### 2. Project Tasks & Deliverables\n",
    " \n",
    "    \n",
    "- In this group project, your team are challenged to perform a full lifecycle ML model development according to the objective of the dataset, which includes the following elements:\n",
    "\n",
    "- Perform exploratory data analysis (EDA), and establish hypotheses of predictive insights you expect to glean from the dataset. \n",
    "\n",
    "- Perform data preparation for ML informed by the EDA findings.\n",
    "\n",
    "- Develop ML model according to hypotheses of predictive insights you gleaned from the dataset. You are required to evaluate at least 3 ML algorithms and assess associated issues i.e. \n",
    "\n",
    "- hyperparameters tuning, performance metrics, model complexity (underfitting/overfitting) etc.  Finally, provide a recommendation of the best algorithm for your ML model.\n",
    "\n",
    "1) Documentation:\n",
    "\n",
    "- Jupyter-Notebook include all coding and technical report i.e. explanations, justifications, reasonings etc. for every finding, strategical decision, action, and choice made. \n",
    "\n",
    "i) Jupyter-notebook provide a comprehensive documentation capability by using the Markdown ( https://www.datacamp.com/community/tutorials/markdown-in-jupyter-notebook).\n",
    "\n",
    "- Executive Summary Report (maximum 1000 words) to provide an overview of the entire lifecycle of the ML model development, written with target audience in mind such as high-level stakeholders, decision makers, directors etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
